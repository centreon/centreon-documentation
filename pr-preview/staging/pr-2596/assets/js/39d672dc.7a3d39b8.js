"use strict";(self.webpackChunkcentreon_docs=self.webpackChunkcentreon_docs||[]).push([[807],{83745:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>m,contentTitle:()=>p,default:()=>N,frontMatter:()=>c,metadata:()=>d,toc:()=>u});n(67294);var a=n(3905),r=n(51715),l=n(7626);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})),e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}const c={id:"installation-4-nodes",title:"Installing a Centreon HA 4-nodes cluster"},p=void 0,d={unversionedId:"installation/installation-of-centreon-ha/installation-4-nodes",id:"version-23.10/installation/installation-of-centreon-ha/installation-4-nodes",title:"Installing a Centreon HA 4-nodes cluster",description:"Prerequisites",source:"@site/versioned_docs/version-23.10/installation/installation-of-centreon-ha/installation-4-nodes.md",sourceDirName:"installation/installation-of-centreon-ha",slug:"/installation/installation-of-centreon-ha/installation-4-nodes",permalink:"/centreon-documentation/pr-preview/staging/pr-2596/docs/installation/installation-of-centreon-ha/installation-4-nodes",draft:!1,editUrl:"https://github.com/centreon/centreon-documentation/edit/staging/versioned_docs/version-23.10/installation/installation-of-centreon-ha/installation-4-nodes.md",tags:[],version:"23.10",lastUpdatedAt:1699359701,formattedLastUpdatedAt:"Nov 7, 2023",frontMatter:{id:"installation-4-nodes",title:"Installing a Centreon HA 4-nodes cluster"},sidebar:"version-23.10/docs",previous:{title:"Installing a Centreon HA 2-nodes cluster",permalink:"/centreon-documentation/pr-preview/staging/pr-2596/docs/installation/installation-of-centreon-ha/installation-2-nodes"},next:{title:"Integrating new pollers in a Centreon-HA cluster",permalink:"/centreon-documentation/pr-preview/staging/pr-2596/docs/installation/installation-of-centreon-ha/integrating-pollers"}},m={},u=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Understanding",id:"understanding",level:3},{value:"Network Flows",id:"network-flows",level:3},{value:"Installed Centreon platform",id:"installed-centreon-platform",level:3},{value:"Quorum Device",id:"quorum-device",level:3},{value:"Defining hosts&#39; names and addresses",id:"defining-hosts-names-and-addresses",level:3},{value:"Configuring centreon-broker",id:"configuring-centreon-broker",level:3},{value:"Link to cbd service",id:"link-to-cbd-service",level:4},{value:"Double output stream toward RRD",id:"double-output-stream-toward-rrd",level:4},{value:"Export the configuration",id:"export-the-configuration",level:4},{value:"Customizing poller reload command",id:"customizing-poller-reload-command",level:3},{value:"System settings",id:"system-settings",level:2},{value:"Kernel network tuning",id:"kernel-network-tuning",level:3},{value:"Name resolution",id:"name-resolution",level:3},{value:"Installing system packages",id:"installing-system-packages",level:3},{value:"Central Servers",id:"central-servers",level:4},{value:"Database Servers",id:"database-servers",level:4},{value:"SSH keys exchange",id:"ssh-keys-exchange",level:3},{value:"<code>centreon</code> account",id:"centreon-account",level:4},{value:"<code>mysql</code> account",id:"mysql-account",level:4},{value:"Configuring the MariaDB database replication",id:"configuring-the-mariadb-database-replication",level:2},{value:"Configuring MariaDB",id:"configuring-mariadb",level:3},{value:"Securing the database server",id:"securing-the-database-server",level:3},{value:"Creating the <code>centreon</code> MariaDB account",id:"creating-the-centreon-mariadb-account",level:3},{value:"Creating the MariaDB replication account",id:"creating-the-mariadb-replication-account",level:3},{value:"Configuring the MariaDB scripts environment variables",id:"configuring-the-mariadb-scripts-environment-variables",level:3},{value:"Switching to read-only mode",id:"switching-to-read-only-mode",level:3},{value:"Synchronizing the databases and enabling MariaDB replication",id:"synchronizing-the-databases-and-enabling-mariadb-replication",level:3},{value:"Setting up the <em>Centreon</em> cluster",id:"setting-up-the-centreon-cluster",level:2},{value:"Configuring the file synchronization service",id:"configuring-the-file-synchronization-service",level:3},{value:"Removing legacy Centreon cron jobs",id:"removing-legacy-centreon-cron-jobs",level:3},{value:"Permission modifications",id:"permission-modifications",level:3},{value:"Stopping and disabling the services",id:"stopping-and-disabling-the-services",level:3},{value:"Creating the cluster",id:"creating-the-cluster",level:3},{value:"Activating the clustering services",id:"activating-the-clustering-services",level:4},{value:"Preparing the server that will function as the <em>quorum device</em>",id:"preparing-the-server-that-will-function-as-the-quorum-device",level:4},{value:"Authenticating to the cluster&#39;s members",id:"authenticating-to-the-clusters-members",level:4},{value:"Creating the cluster",id:"creating-the-cluster-1",level:4},{value:"Creating the <em>Quorum Device</em>",id:"creating-the-quorum-device",level:4},{value:"Creating the MariaDB cluster resources",id:"creating-the-mariadb-cluster-resources",level:3},{value:"Primary &amp; Secondary MySQL Processes",id:"primary--secondary-mysql-processes",level:4},{value:"MariaDB Virtual IP Address",id:"mariadb-virtual-ip-address",level:4},{value:"Creating the clone resources",id:"creating-the-clone-resources",level:3},{value:"PHP8 resource",id:"php8-resource",level:5},{value:"RRD broker resource",id:"rrd-broker-resource",level:5},{value:"Creating the <em>centreon</em> resource group",id:"creating-the-centreon-resource-group",level:3},{value:"Web VIP address",id:"web-vip-address",level:4},{value:"Httpd service",id:"httpd-service",level:4},{value:"Gorgone service",id:"gorgone-service",level:4},{value:"centreon-central-sync service",id:"centreon-central-sync-service",level:4},{value:"SQL Broker",id:"sql-broker",level:4},{value:"Centengine service",id:"centengine-service",level:4},{value:"Centreontrapd service",id:"centreontrapd-service",level:4},{value:"Snmptrapd service",id:"snmptrapd-service",level:4},{value:"Resource constraints",id:"resource-constraints",level:3},{value:"Activate the cluster and check the operating state of the resources",id:"activate-the-cluster-and-check-the-operating-state-of-the-resources",level:3},{value:"Enable resources",id:"enable-resources",level:4},{value:"Checking the state of the cluster",id:"checking-the-state-of-the-cluster",level:3},{value:"Checking the states of the resources",id:"checking-the-states-of-the-resources",level:4},{value:"Disabled resources",id:"disabled-resources",level:4},{value:"Checking the database replication thread",id:"checking-the-database-replication-thread",level:4},{value:"Checking the constraints",id:"checking-the-constraints",level:4},{value:"Modifying the Centreon configuration files",id:"modifying-the-centreon-configuration-files",level:2},{value:"Modifying central-broker-master outputs",id:"modifying-central-broker-master-outputs",level:3},{value:"Exporting configuration",id:"exporting-configuration",level:3},{value:"Modification of the three configuration files",id:"modification-of-the-three-configuration-files",level:3},{value:"Integrating pollers",id:"integrating-pollers",level:2}],h={toc:u},k="wrapper";function N(e){var{components:t}=e,n=i(e,["components"]);return(0,a.kt)(k,s(function(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{},a=Object.keys(n);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(n).filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable})))),a.forEach((function(t){o(e,t,n[t])}))}return e}({},h,n),{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,a.kt)("h3",{id:"understanding"},"Understanding"),(0,a.kt)("p",null,"Before applying this procedure, you should have a good knowledge of Linux OS, Centreon,\nand Pacemaker clustering tools in order to have a proper understanding of what is being done."),(0,a.kt)("h3",{id:"network-flows"},"Network Flows"),(0,a.kt)("p",null,"In addition to the necessary flows described in the ",(0,a.kt)("a",{parentName:"p",href:"/centreon-documentation/pr-preview/staging/pr-2596/docs/installation/architectures#tables-of-network-flows"},"official documentation"),",\nyou will need to open the following flows:"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:"left"},"From"),(0,a.kt)("th",{parentName:"tr",align:"left"},"Destination"),(0,a.kt)("th",{parentName:"tr",align:"left"},"Protocol"),(0,a.kt)("th",{parentName:"tr",align:"left"},"Port"),(0,a.kt)("th",{parentName:"tr",align:"left"},"Application"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Active Central Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Passive Central Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"SSH"),(0,a.kt)("td",{parentName:"tr",align:"left"},"TCP 22"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Synchronization of configuration files (Must also be open from passive to active node)")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Active Central Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Passive Central Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"BDDO"),(0,a.kt)("td",{parentName:"tr",align:"left"},"TCP 5670"),(0,a.kt)("td",{parentName:"tr",align:"left"},"RRDs synchronization (Must also be open from passive to active node)")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Active Database Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Passive Database Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"MySQL"),(0,a.kt)("td",{parentName:"tr",align:"left"},"TCP 3306"),(0,a.kt)("td",{parentName:"tr",align:"left"},"MySQL synchronization (Must also be open from passive to active node)")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Active Database Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Passive Database Server"),(0,a.kt)("td",{parentName:"tr",align:"left"},"SSH"),(0,a.kt)("td",{parentName:"tr",align:"left"},"TCP 22"),(0,a.kt)("td",{parentName:"tr",align:"left"},"MySQL synchronization (Must also be open from passive to active node)")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Corosync"),(0,a.kt)("td",{parentName:"tr",align:"left"},"UDP 5404"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Communication inside the cluster (Multicast)")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Corosync"),(0,a.kt)("td",{parentName:"tr",align:"left"},"UDP 5405"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Communication inside the cluster (Unicast)")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"PCS"),(0,a.kt)("td",{parentName:"tr",align:"left"},"TCP 2224"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Communication inside the cluster")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Central Servers + DB + QDevice"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Corosync"),(0,a.kt)("td",{parentName:"tr",align:"left"},"TCP 5403"),(0,a.kt)("td",{parentName:"tr",align:"left"},"Communication with the QDevice")))),(0,a.kt)("h3",{id:"installed-centreon-platform"},"Installed Centreon platform"),(0,a.kt)("p",null,"A Centreon HA cluster can only be installed on top of an operating Centreon platform. Before following this procedure, it is mandatory that ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("a",{parentName:"strong",href:"/centreon-documentation/pr-preview/staging/pr-2596/docs/installation/introduction"},"this installation procedure"))," has already been completed and that ",(0,a.kt)("strong",{parentName:"p"},"about 5 GB free space has been spared on the LVM volume group")," that carries the MariaDB data directory (",(0,a.kt)("inlineCode",{parentName:"p"},"/var/lib/mysql")," mount point by default)."),(0,a.kt)("p",null,"The output of the ",(0,a.kt)("inlineCode",{parentName:"p"},"vgs")," command must look like this: (pay attention to the value under ",(0,a.kt)("inlineCode",{parentName:"p"},"VFree"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"  VG                    #PV #LV #SN Attr   VSize   VFree \n  centos_centreon-c1      1   5   0 wz--n- <31,00g <5,00g\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"MariaDB files ",(0,a.kt)("inlineCode",{parentName:"li"},"ibdata*")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"ib_logfile*"),' must be in the "datadir" directory or in a subdirectory (scripts ',(0,a.kt)("inlineCode",{parentName:"li"},"centreondb-smooth-backup.sh")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"mysql-sync-bigdb.sh")," are not compatible with this operation);"),(0,a.kt)("li",{parentName:"ul"},"MariaDB files ",(0,a.kt)("inlineCode",{parentName:"li"},"log-bin*")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"relay-log*"),' can be located in a directory (or a subdirectory) different from "datadir". They can also be on a different logical volume (',(0,a.kt)("inlineCode",{parentName:"li"},"lvm"),') than "datadir". However, the logical volume must be located in the volume group where "datadir" is stored.')),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"WARNING:")," If these particular prerequisites are not effective, the database synchronization method described below will not work.")),(0,a.kt)("h3",{id:"quorum-device"},"Quorum Device"),(0,a.kt)("p",null,"In order to keep the cluster safe from split-brain issues, a third server is mandatory to resolve the master's election in the event of a connection loss. The role of Quorum Device can be held by a poller of the monitoring platform."),(0,a.kt)("p",null,"In order to adhere to best practices and be as resilient as possible, the Quorum server\nshould be at a different site than the two primary nodes, with independent network connections."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"WARNING:")," Make sure SELinux and Firewalld are disabled.")),(0,a.kt)("h3",{id:"defining-hosts-names-and-addresses"},"Defining hosts' names and addresses"),(0,a.kt)("p",null,"In this procedure, we will refer to characteristics that are bound to change from one platform to another (such as IP addresses) by the following macros:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@CENTRAL_MASTER_IPADDR@"),": primary central server's IP address"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@CENTRAL_MASTER_NAME@"),": primary central server's name (must be identical to ",(0,a.kt)("inlineCode",{parentName:"li"},"hostname -s"),")"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@CENTRAL_SLAVE_IPADDR@"),": secondary central server's IP address"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@CENTRAL_SLAVE_NAME@"),": secondary central server's name (must be identical to ",(0,a.kt)("inlineCode",{parentName:"li"},"hostname -s"),")"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@DATABASE_MASTER_IPADDR@"),": primary database server's IP address"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@DATABASE_MASTER_NAME@"),": primary database server's FQDN (must be identical to: ",(0,a.kt)("inlineCode",{parentName:"li"},"hostname -s"),")"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@DATABASE_SLAVE_IPADDR@"),": secondary database server's IP address "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@DATABASE_SLAVE_NAME@"),": secondary database server's FQDN (must be identical to: ",(0,a.kt)("inlineCode",{parentName:"li"},"hostname -s"),")"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@QDEVICE_IPADDR@"),": quorum device's IP address"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@QDEVICE_NAME@"),": quorum device's name (must be identical to ",(0,a.kt)("inlineCode",{parentName:"li"},"hostname -s"),")"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@MARIADB_REPL_USER@"),":  MariaDB replication login (default: ",(0,a.kt)("inlineCode",{parentName:"li"},"centreon-repl"),")"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@MARIADB_REPL_PASSWD@"),": MariaDB replication password"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@MARIADB_CENTREON_USER@"),": MariaDB Centreon login (default: ",(0,a.kt)("inlineCode",{parentName:"li"},"centreon"),")"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@MARIADB_CENTREON_PASSWD@"),": MariaDB Centreon "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_IPADDR@"),": virtual IP address of the cluster"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_IFNAME@"),": network device carrying the cluster's VIP"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_CIDR_NETMASK@"),": subnet mask length in bits (e.g. 24)"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_BROADCAST_IPADDR@"),": cluster's VIP broadcast address"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_SQL_IPADDR@"),": virtual IP address of the SQL cluster"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_SQL_IFNAME@"),": network device carrying the SQL cluster's VIP"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_SQL_CIDR_NETMASK@"),": SQL Cluster subnet mask length in bits (e.g. 24)"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@VIP_SQL_BROADCAST_IPADDR@"),": cluster's VIP SQL broadcast address"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"@CENTREON_CLUSTER_PASSWD@"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"hacluster")," user's password")),(0,a.kt)("h3",{id:"configuring-centreon-broker"},"Configuring centreon-broker"),(0,a.kt)("h4",{id:"link-to-cbd-service"},"Link to cbd service"),(0,a.kt)("p",null,"On a standard Centreon platform, cbd service manages two processes of ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon-broker-daemon")," (",(0,a.kt)("inlineCode",{parentName:"p"},"cbd"),"):"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"central-broker-master"),': also called "central broker" or "SQL broker", redirects input-output from pollers to database, RRD broker, and so on.'),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"central-rrd-master"),': also called "RRD broker", receives the stream from the central broker and updates the RRD binary data files (used to display graphs).')),(0,a.kt)("p",null,"In the context of a ",(0,a.kt)("em",{parentName:"p"},"Centreon HA")," cluster, both broker processes will be handled by a separate service, managed by the cluster."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"central-broker-master")," known as the resource ",(0,a.kt)("inlineCode",{parentName:"li"},"cbd_central_broker"),", linked to ",(0,a.kt)("em",{parentName:"li"},"systemd")," service ",(0,a.kt)("inlineCode",{parentName:"li"},"cbd-sql")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"central-rrd-master")," known as the clone resource ",(0,a.kt)("inlineCode",{parentName:"li"},"cbd_rrd"),", linked to ",(0,a.kt)("em",{parentName:"li"},"systemd")," ",(0,a.kt)("inlineCode",{parentName:"li"},"cbd")," service, the standard broker service of Centreon.")),(0,a.kt)("p",null,"To ensure that everything goes well, you will have to unlink central-broker-master from the ",(0,a.kt)("inlineCode",{parentName:"p"},"cbd"),' service by checking "No" for parameter "Link to cbd service" in ',(0,a.kt)("em",{parentName:"p"},"Configuration")," > ",(0,a.kt)("em",{parentName:"p"},"Pollers")," > ",(0,a.kt)("em",{parentName:"p"},"Broker configuration")," > ",(0,a.kt)("em",{parentName:"p"},"central-broker-master")," under the ",(0,a.kt)("em",{parentName:"p"},"General")," tab."),(0,a.kt)("h4",{id:"double-output-stream-toward-rrd"},"Double output stream toward RRD"),(0,a.kt)("p",null,"In the event of a cluster switch, you will expect the newly elected master central server to be able to display the metrics graphs, which requires all RRD data files to be up to date on both nodes. In order to fulfill this condition, you will double the central broker output stream and send it to both RRD broker processes. You can configure this in the same menu as above, this time under the ",(0,a.kt)("em",{parentName:"p"},"Output")," tab. The parameters that must be changed are:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'In the first "IPv4" output, replace "localhost" with ',(0,a.kt)("inlineCode",{parentName:"li"},"@CENTRAL_MASTER_IPADDR@"),' in the "Host to connect to" field.')),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Output IPv4"),(0,a.kt)("th",{parentName:"tr",align:null}))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Name"),(0,a.kt)("td",{parentName:"tr",align:null},"centreon-broker-master-rrd")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Connection port"),(0,a.kt)("td",{parentName:"tr",align:null},"5670")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Host to connect to"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"@CENTRAL_MASTER_IPADDR@"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Buffering timeout"),(0,a.kt)("td",{parentName:"tr",align:null},"0")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Retry interval"),(0,a.kt)("td",{parentName:"tr",align:null},"60")))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'Add another "IPv4" output, similar to the first one, named "centreon-broker-slave-rrd" for example, directed toward ',(0,a.kt)("inlineCode",{parentName:"li"},"@CENTRAL_SLAVE_IPADDR@"),".")),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Output IPv4"),(0,a.kt)("th",{parentName:"tr",align:null}))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Name"),(0,a.kt)("td",{parentName:"tr",align:null},"centreon-broker-slave-rrd")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Connection port"),(0,a.kt)("td",{parentName:"tr",align:null},"5670")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Host to connect to"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"@CENTRAL_SLAVE_IPADDR@"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Buffering timeout"),(0,a.kt)("td",{parentName:"tr",align:null},"0")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Retry interval"),(0,a.kt)("td",{parentName:"tr",align:null},"60")))),(0,a.kt)("h4",{id:"export-the-configuration"},"Export the configuration"),(0,a.kt)("p",null,'Once the above actions have been done, export the central poller configuration files to apply these changes. Select the central poller and export the configuration with the "Move Export Files" option checked.'),(0,a.kt)("p",null,"All the above actions should be applied either to both nodes or to ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_MASTER_NAME@")," only, and the exported files should be copied to ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_SLAVE_NAME@"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"rsync -a /etc/centreon-broker/*json @CENTRAL_SLAVE_IPADDR@:/etc/centreon-broker/\n")),(0,a.kt)("h3",{id:"customizing-poller-reload-command"},"Customizing poller reload command"),(0,a.kt)("p",null,'You might not be aware that the central broker daemon must be reloaded every time you update your central poller\'s configuration, hence the "Centreon Broker reload command" parameter in ',(0,a.kt)("em",{parentName:"p"},"Configuration > Pollers > Central"),"."),(0,a.kt)("p",null,"As stated above, the centreon-broker processes will be divided into ",(0,a.kt)("inlineCode",{parentName:"p"},"cbd")," (for RRD) and ",(0,a.kt)("inlineCode",{parentName:"p"},"cbd-sql")," (for central broker) services. With this in mind, the service that needs to be reloaded is ",(0,a.kt)("inlineCode",{parentName:"p"},"cbd-sql"),", and no longer ",(0,a.kt)("inlineCode",{parentName:"p"},"cbd"),'. So you will have to set the "Centreon Broker reload command" parameter to ',(0,a.kt)("inlineCode",{parentName:"p"},"service cbd-sql reload"),"."),(0,a.kt)("h2",{id:"system-settings"},"System settings"),(0,a.kt)("p",null,"Before actually setting the cluster up, some system prerequisites must be satisfied."),(0,a.kt)("h3",{id:"kernel-network-tuning"},"Kernel network tuning"),(0,a.kt)("p",null,"In order to improve the reliability of the cluster, and since ",(0,a.kt)("em",{parentName:"p"},"Centreon HA")," only supports IPv4, we recommend applying the following kernel settings to all your Centreon servers (including pollers):"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cat >> /etc/sysctl.conf <<EOF\nnet.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv4.tcp_retries2 = 3\nnet.ipv4.tcp_keepalive_time = 200\nnet.ipv4.tcp_keepalive_probes = 2\nnet.ipv4.tcp_keepalive_intvl = 2\nEOF\nsystemctl restart NetworkManager\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cat >> /etc/sysctl.conf <<EOF\nnet.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv4.tcp_retries2 = 3\nnet.ipv4.tcp_keepalive_time = 200\nnet.ipv4.tcp_keepalive_probes = 2\nnet.ipv4.tcp_keepalive_intvl = 2\nEOF\nreboot\n")))),(0,a.kt)("h3",{id:"name-resolution"},"Name resolution"),(0,a.kt)("p",null,"So that the ",(0,a.kt)("em",{parentName:"p"},"Centreon HA")," cluster can stay in operation in the event of a DNS service breakdown, all the cluster nodes must know each other by name without DNS, using ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/hosts"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'cat >/etc/hosts <<"EOF"\n127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4\n@CENTRAL_MASTER_IPADDR@ @CENTRAL_MASTER_NAME@\n@CENTRAL_SLAVE_IPADDR@ @CENTRAL_SLAVE_NAME@\n@DATABASE_MASTER_IPADDR@ @DATABASE_MASTER_NAME@\n@DATABASE_SLAVE_IPADDR@ @DATABASE_SLAVE_NAME@\n@QDEVICE_IPADDR@ @QDEVICE_NAME@\nEOF\n')),(0,a.kt)("p",null,"From here, ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_MASTER_NAME@"),' will be named the "primary server/node" and ',(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_SLAVE_NAME@"),' the "secondary server/node". This designation is arbitrary; the two nodes will of course be interchangeable once the setup is complete.'),(0,a.kt)("h3",{id:"installing-system-packages"},"Installing system packages"),(0,a.kt)("p",null,"Centreon offers a package named ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon-ha-web")," for the Central Servers and a package ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon-ha-common")," for the Database servers, providing all the files and dependencies required by a Centreon cluster."),(0,a.kt)("h4",{id:"central-servers"},"Central Servers"),(0,a.kt)("p",null,"These packages must be installed on both Central Servers (Except Quorum):"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma Linux 8",label:"Alma Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf config-manager --enable ha\ndnf install centreon-ha-web pcs pacemaker corosync corosync-qdevice\n"))),(0,a.kt)(l.Z,{value:"RHEL 8",label:"RHEL 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf -y install dnf-plugins-core https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\nsubscription-manager repos --enable rhel-8-for-x86_64-highavailability-rpms\ndnf install centreon-ha-web pcs pacemaker corosync corosync-qdevice\n"))),(0,a.kt)(l.Z,{value:"Oracle Linux 8",label:"Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf config-manager --enable ol8_addons\ndnf install centreon-ha-web pcs pacemaker corosync corosync-qdevice\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"apt update && apt install centreon-ha-web pcs pacemaker corosync corosync-qdevice \n")))),(0,a.kt)("h4",{id:"database-servers"},"Database Servers"),(0,a.kt)("p",null,"These packages must be installed on both Database Servers (Except Quorum):"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma Linux 8",label:"Alma Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf config-manager --enable ha\ndnf install centreon-ha-common pcs pacemaker corosync corosync-qdevice\n"))),(0,a.kt)(l.Z,{value:"RHEL 8",label:"RHEL 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf -y install dnf-plugins-core https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\nsubscription-manager repos --enable rhel-8-for-x86_64-highavailability-rpms\ndnf install centreon-ha-common pcs pacemaker corosync corosync-qdevice\n"))),(0,a.kt)(l.Z,{value:"Oracle Linux 8",label:"Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf config-manager --enable ol8_addons\ndnf install centreon-ha-common pcs pacemaker corosync corosync-qdevice\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"apt update && apt install centreon-ha-common pcs pacemaker corosync corosync-qdevice \n")))),(0,a.kt)("h3",{id:"ssh-keys-exchange"},"SSH keys exchange"),(0,a.kt)("p",null,"SSH key-based authentication must be set so that files and commands can be sent from one node to another by UNIX accounts:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"mysql")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"centreon"))),(0,a.kt)("p",null,"There are two ways of exchanging such keys:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"By using the ",(0,a.kt)("inlineCode",{parentName:"li"},"ssh-copy-id")," command: needs to be able to log in to remote host using a password. It is however unsafe for such system accounts to have a password authentication available. If you choose this method, we advise you to revoke the password afterward with these commands: ",(0,a.kt)("inlineCode",{parentName:"li"},"passwd -d centreon")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"passwd -d mysql"),"."),(0,a.kt)("li",{parentName:"ul"},"By manually copying the public key in ",(0,a.kt)("inlineCode",{parentName:"li"},"~/.ssh/authorized_keys"),". This method is safer.")),(0,a.kt)("p",null,"The second method will be documented below."),(0,a.kt)("h4",{id:"centreon-account"},(0,a.kt)("inlineCode",{parentName:"h4"},"centreon")," account"),(0,a.kt)("p",null,"Switch to ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon"),"'s bash environment on both nodes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"su - centreon\n")),(0,a.kt)("p",null,"Then run these commands on both nodes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"ssh-keygen -t ed25519 -a 100\ncat ~/.ssh/id_ed25519.pub\n")),(0,a.kt)("p",null,"Once done, copy the content of the public key file displayed by ",(0,a.kt)("inlineCode",{parentName:"p"},"cat")," and paste it to ",(0,a.kt)("inlineCode",{parentName:"p"},"~/.ssh/authorized_keys")," (must be created) on the other node, and then apply the correct file permissions (still as user ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"chmod 600 ~/.ssh/authorized_keys\n")),(0,a.kt)("p",null,"The key exchange must be validated by an initial connection from each node to the other in order to accept and register the peer node's SSH fingerprint (still as user ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"ssh <peer node hostname>\n")),(0,a.kt)("p",null,"Then exit the ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon")," session by typing ",(0,a.kt)("inlineCode",{parentName:"p"},"exit")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"Ctrl-D"),"."),(0,a.kt)("h4",{id:"mysql-account"},(0,a.kt)("inlineCode",{parentName:"h4"},"mysql")," account"),(0,a.kt)("p",null,"For the ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql")," account, the procedure is slightly different because this user normally has neither a home directory nor the ability to open a Shell session. These commands must be run on both nodes as well:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl stop mysql\nmkdir /home/mysql\nchown mysql: /home/mysql\nusermod -d /home/mysql mysql\nusermod -s /bin/bash mysql\nsystemctl start mysql\nsu - mysql\n")),(0,a.kt)("p",null,"Once in ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql"),"'s ",(0,a.kt)("inlineCode",{parentName:"p"},"bash")," envinronment, run these commands on both nodes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"ssh-keygen -t ed25519 -a 100\ncat ~/.ssh/id_ed25519.pub\n")),(0,a.kt)("p",null,"Once done, copy the content of the public key file displayed by ",(0,a.kt)("inlineCode",{parentName:"p"},"cat")," and paste it to ",(0,a.kt)("inlineCode",{parentName:"p"},"~/.ssh/authorized_keys")," (must be created) on the other node, and then apply the correct file permissions (still as user",(0,a.kt)("inlineCode",{parentName:"p"},"mysql"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"chmod 600 ~/.ssh/authorized_keys\n")),(0,a.kt)("p",null,"The key exchange must be validated by an initial connection from each node to the other in order to accept and register the peer node's SSH fingerprint (still as user ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"ssh <peer node hostname>\n")),(0,a.kt)("p",null,"Then exit the ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql")," session by typing ",(0,a.kt)("inlineCode",{parentName:"p"},"exit")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"Ctrl-D"),"."),(0,a.kt)("h2",{id:"configuring-the-mariadb-database-replication"},"Configuring the MariaDB database replication"),(0,a.kt)("p",null,"A Master-Slave MariaDB cluster will be set up so that everything is synchronized in real time. "),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Note"),": unless otherwise stated, each of the following steps must be run ",(0,a.kt)("strong",{parentName:"p"},"on both database nodes"),"."),(0,a.kt)("h3",{id:"configuring-mariadb"},"Configuring MariaDB"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("p",null,"For both optimization and cluster reliability purposes, you need to add these tuning options to the MariaDB configuration in the ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/my.cnf.d/server.cnf")," file. By default, the ",(0,a.kt)("inlineCode",{parentName:"p"},"[server]")," section of this file is empty. Paste the following lines (some need to be modified) into this section:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ini"},"[server]\nserver-id=1 # SET TO 1 FOR MASTER AND 2 FOR SLAVE\n#read_only\nlog-bin=mysql-bin\nbinlog-do-db=centreon\nbinlog-do-db=centreon_storage\ninnodb_flush_log_at_trx_commit=1\nsync_binlog=1\nbinlog_format=MIXED\nslave_compressed_protocol=1\nslave_parallel_mode=conservative\ndatadir=/var/lib/mysql\npid-file=/var/lib/mysql/mysql.pid\nskip-slave-start\nlog-slave-updates\ngtid_strict_mode=ON\nexpire_logs_days=7\nignore-db-dir=lost+found\n\n# Tuning standard Centreon\ninnodb_file_per_table=1\nopen_files_limit=32000\nkey_buffer_size=256M\nsort_buffer_size=32M\njoin_buffer_size=4M\nthread_cache_size=64\nread_buffer_size=512K\nread_rnd_buffer_size=256K\nmax_allowed_packet=64M\n# Uncomment for 4 Go Ram\n#innodb_buffer_pool_size=512M\n# Uncomment for 8 Go Ram\n#innodb_buffer_pool_size=1G\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("p",null,"For both optimization and cluster reliability purposes, you need to add these tuning options to the MariaDB configuration in the ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/mysql/mariadb.conf.d/50-server.cnf")," file. By default, the ",(0,a.kt)("inlineCode",{parentName:"p"},"[server]")," section of this file is empty. Paste the following lines (some need to be modified) into this section:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ini"},"[server]\nserver-id=1 # SET TO 1 FOR MASTER AND 2 FOR SLAVE\n#read_only\nlog-bin=mysql-bin\nbinlog-do-db=centreon\nbinlog-do-db=centreon_storage\ninnodb_flush_log_at_trx_commit=1\nsync_binlog=1\nbinlog_format=MIXED\nslave_compressed_protocol=1\nslave_parallel_mode=conservative\ndatadir=/var/lib/mysql\npid-file=/run/mysqld/mysql.pid\nskip-slave-start\nlog-slave-updates\ngtid_strict_mode=ON\nexpire_logs_days=7\nignore-db-dir=lost+found\n\n# Tuning standard Centreon\ninnodb_file_per_table=1\nopen_files_limit=32000\nkey_buffer_size=256M\nsort_buffer_size=32M\njoin_buffer_size=4M\nthread_cache_size=64\nread_buffer_size=512K\nread_rnd_buffer_size=256K\nmax_allowed_packet=64M\n# Uncomment for 4 Go Ram\n#innodb_buffer_pool_size=512M\n# Uncomment for 8 Go Ram\n#innodb_buffer_pool_size=1G\n")))),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"Important:")," the value of ",(0,a.kt)("inlineCode",{parentName:"p"},"server-id")," must be different from one server to the other. The values suggested in the comment 1 => Master and 2 => Slave are not mandatory, but recommended.")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Reminder:")," Remember to uncomment the right value for ",(0,a.kt)("inlineCode",{parentName:"p"},"innodb_buffer_pool_size")," according to your own servers' memory size."),(0,a.kt)("p",null,"To apply the new configuration, restart the database server:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl restart mysql\n")),(0,a.kt)("p",null,"Make sure the restart went well:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl status mysql\n")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"Warning:")," Other files in ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/my.cnf.d/"),", such as ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon.cnf"),", will be ignored from now on. Any customization will have to be added to ",(0,a.kt)("inlineCode",{parentName:"p"},"server.cnf"),".")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"Warning:")," Remember to change the parameter ",(0,a.kt)("inlineCode",{parentName:"p"},"Mysql configuration file path")," in ",(0,a.kt)("strong",{parentName:"p"},"Administration > Parameters > Backup"))),(0,a.kt)("h3",{id:"securing-the-database-server"},"Securing the database server"),(0,a.kt)("p",null,"To avoid unnecessary exposure of your database, you should restrict access to it as much as possible. The ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql_secure_installation")," command will help you apply some basic security principles. You just need to run this command and let yourself be guided, choosing the recommended option at every step. We suggest you choose a strong password."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"mysql_secure_installation\n")),(0,a.kt)("h3",{id:"creating-the-centreon-mariadb-account"},"Creating the ",(0,a.kt)("inlineCode",{parentName:"h3"},"centreon")," MariaDB account"),(0,a.kt)("p",null,"First log in as ",(0,a.kt)("inlineCode",{parentName:"p"},"root")," on both database servers (using the newly-defined password):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"mysql -p\n")),(0,a.kt)("p",null,"Then, on both sides, paste the following SQL commands to the MariaDB prompt to create the application user (default: ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon"),"). Of course, you will replace the macros first:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE USER '@MARIADB_CENTREON_USER@'@'@DATABASE_SLAVE_IPADDR@' IDENTIFIED BY '@MARIADB_CENTREON_PASSWD@';\nGRANT ALL PRIVILEGES ON centreon.* TO '@MARIADB_CENTREON_USER@'@'@DATABASE_SLAVE_IPADDR@';\nGRANT ALL PRIVILEGES ON centreon_storage.* TO '@MARIADB_CENTREON_USER@'@'@DATABASE_SLAVE_IPADDR@';\n\nCREATE USER '@MARIADB_CENTREON_USER@'@'@DATABASE_MASTER_IPADDR@' IDENTIFIED BY '@MARIADB_CENTREON_PASSWD@';\nGRANT ALL PRIVILEGES ON centreon.* TO '@MARIADB_CENTREON_USER@'@'@DATABASE_MASTER_IPADDR@';\nGRANT ALL PRIVILEGES ON centreon_storage.* TO '@MARIADB_CENTREON_USER@'@'@DATABASE_MASTER_IPADDR@';\n")),(0,a.kt)("p",null,"Optionally, you can allow these privileges to be used from the Central Cluster.  This will make some administration scripts runnable from every node."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE USER '@MARIADB_CENTREON_USER@'@'@CENTRAL_SLAVE_IPADDR@' IDENTIFIED BY '@MARIADB_CENTREON_PASSWD@';\nGRANT ALL PRIVILEGES ON centreon.* TO '@MARIADB_CENTREON_USER@'@'@CENTRAL_SLAVE_IPADDR@';\nGRANT ALL PRIVILEGES ON centreon_storage.* TO '@MARIADB_CENTREON_USER@'@'@CENTRAL_SLAVE_IPADDR@';\n\nCREATE USER '@MARIADB_CENTREON_USER@'@'@CENTRAL_MASTER_IPADDR@' IDENTIFIED BY '@MARIADB_CENTREON_PASSWD@';\nGRANT ALL PRIVILEGES ON centreon.* TO '@MARIADB_CENTREON_USER@'@'@CENTRAL_MASTER_IPADDR@';\nGRANT ALL PRIVILEGES ON centreon_storage.* TO '@MARIADB_CENTREON_USER@'@'@CENTRAL_MASTER_IPADDR@';\n")),(0,a.kt)("p",null,"When upgrading to centreon-ha from an existing Centreon platform or an OVA/OVF VM deployment, update the ",(0,a.kt)("inlineCode",{parentName:"p"},"'@MARIADB_CENTREON_USER@'@'localhost'")," password:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER USER '@MARIADB_CENTREON_USER@'@'localhost' IDENTIFIED BY '@MARIADB_CENTREON_PASSWD@';\n")),(0,a.kt)("h3",{id:"creating-the-mariadb-replication-account"},"Creating the MariaDB replication account"),(0,a.kt)("p",null,"Still in the same prompt, create the replication user (default: ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon-repl"),"):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"GRANT SHUTDOWN, PROCESS, RELOAD, SUPER, SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* \nTO '@MARIADB_REPL_USER@'@'localhost' IDENTIFIED BY '@MARIADB_REPL_PASSWD@';\n\nGRANT SHUTDOWN, PROCESS, RELOAD, SUPER, SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* \nTO '@MARIADB_REPL_USER@'@'@DATABASE_SLAVE_IPADDR@' IDENTIFIED BY '@MARIADB_REPL_PASSWD@';\n\nGRANT SHUTDOWN, PROCESS, RELOAD, SUPER, SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* \nTO '@MARIADB_REPL_USER@'@'@DATABASE_MASTER_IPADDR@' IDENTIFIED BY '@MARIADB_REPL_PASSWD@';\n")),(0,a.kt)("p",null,"Optionally, you can allow these privileges to be used from the Central Cluster. This will make some administration scripts runnable from every node."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"GRANT SHUTDOWN, PROCESS, RELOAD, SUPER, SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* \nTO '@MARIADB_REPL_USER@'@'@CENTRAL_SLAVE_IPADDR@' IDENTIFIED BY '@MARIADB_REPL_PASSWD@';\n\nGRANT SHUTDOWN, PROCESS, RELOAD, SUPER, SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* \nTO '@MARIADB_REPL_USER@'@'@CENTRAL_MASTER_IPADDR@' IDENTIFIED BY '@MARIADB_REPL_PASSWD@';\n")),(0,a.kt)("h3",{id:"configuring-the-mariadb-scripts-environment-variables"},"Configuring the MariaDB scripts environment variables"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/centreon-ha/mysql-resources.sh")," file declares environment variables that must be configured so that the ",(0,a.kt)("em",{parentName:"p"},"Centreon HA")," scripts dedicated to MariaDB can work properly. These variables must be assigned the chosen values for the macros."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"#!/bin/bash\n\n###############################\n# Database access credentials #\n###############################\n\nDBHOSTNAMEMASTER='@DATABASE_MASTER_NAME@'\nDBHOSTNAMESLAVE='@DATABASE_SLAVE_NAME@'\nDBREPLUSER='@MARIADB_REPL_USER@'\nDBREPLPASSWORD='@MARIADB_REPL_PASSWD@'\nDBROOTUSER='@MARIADB_REPL_USER@'\nDBROOTPASSWORD='@MARIADB_REPL_PASSWD@'\nCENTREON_DB='centreon'\nCENTREON_STORAGE_DB='centreon_storage'\n\n###############################\n")),(0,a.kt)("p",null,"To make sure that all the previous steps have been successful, and that the correct names, logins and passwords have been entered in the configuration bash file, run this command on database nodes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"/usr/share/centreon-ha/bin/mysql-check-status.sh\n")),(0,a.kt)("p",null,"The expected output is:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"Connection MASTER Status '@DATABASE_MASTER_NAME@' [OK]\nConnection SLAVE Status '@DATABASE_SLAVE_NAME@' [OK]\nSlave Thread Status [KO]\nError reports:\n    No slave (maybe because we cannot check a server).\nPosition Status [SKIP]\n!Error reports:\n    Skip because we can't identify a unique slave.\n")),(0,a.kt)("p",null,"What matters here is that the first two connection tests are ",(0,a.kt)("inlineCode",{parentName:"p"},"OK"),"."),(0,a.kt)("h3",{id:"switching-to-read-only-mode"},"Switching to read-only mode"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("p",null,"Now that everything is well configured, enable the ",(0,a.kt)("inlineCode",{parentName:"p"},"read_only")," on both database servers by uncommenting (",(0,a.kt)("em",{parentName:"p"},"i.e.")," removing the ",(0,a.kt)("inlineCode",{parentName:"p"},"#")," at the beginning of the line) this instruction in the ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/my.cnf.d/server.cnf")," file:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Primary node:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ini"},"[server]\nserver-id=1\nread_only\nlog-bin=mysql-bin\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Secondary node:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ini"},"[server]\nserver-id=2\nread_only\nlog-bin=mysql-bin\n")),(0,a.kt)("p",null,"Then apply this change by restarting MariaDB on both nodes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl restart mysql\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("p",null,"Now that everything is well configured, enable the ",(0,a.kt)("inlineCode",{parentName:"p"},"read_only")," on both database servers by uncommenting (",(0,a.kt)("em",{parentName:"p"},"i.e.")," removing the ",(0,a.kt)("inlineCode",{parentName:"p"},"#")," at the beginning of the line) this instruction in the ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/mysql/mariadb.conf.d/50-server.cnf")," file:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Primary node")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ini"},"[server]\nserver-id=1\nread_only\nlog-bin=mysql-bin\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Secondary node")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-ini"},"[server]\nserver-id=2\nread_only\nlog-bin=mysql-bin\n")),(0,a.kt)("p",null,"Next, apply this change by restarting MariaDB on both nodes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl restart mariadb\n")))),(0,a.kt)("h3",{id:"synchronizing-the-databases-and-enabling-mariadb-replication"},"Synchronizing the databases and enabling MariaDB replication"),(0,a.kt)("p",null,"In the process of synchronizing the databases, you will first stop the secondary database process so that its data can be overwritten by the primary node's data. "),(0,a.kt)("p",null,"Run this command ",(0,a.kt)("strong",{parentName:"p"},"on the secondary node:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl stop mysql\n")),(0,a.kt)("p",null,"It is important to make sure that MariaDB is completely shut down. Run this command and check that it returns no output:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"ps -ef | grep mariadb[d]\n")),(0,a.kt)("p",null,"In case one or more processes are still alive, run this other command (it will prompt for the MariaDB root password):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"mysqladmin -p shutdown\n")),(0,a.kt)("p",null,"Once the service is stopped ",(0,a.kt)("strong",{parentName:"p"},"on the secondary node"),", run the synchronization script ",(0,a.kt)("strong",{parentName:"p"},"from the primary database node"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"/usr/share/centreon-ha/bin/mysql-sync-bigdb.sh\n")),(0,a.kt)("p",null,"This script will perform the following actions:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"checking that MariaDB is stopped on the secondary node"),(0,a.kt)("li",{parentName:"ul"},"stopping MariaDB on the primary node"),(0,a.kt)("li",{parentName:"ul"},"mounting an LVM snapshot on the same volume group that holds ",(0,a.kt)("inlineCode",{parentName:"li"},"/var/lib/mysql")," (or whatever mount point holds the MariaDB data files)"),(0,a.kt)("li",{parentName:"ul"},"starting MariaDB again on the primary node"),(0,a.kt)("li",{parentName:"ul"},"recording the current position in the binary log"),(0,a.kt)("li",{parentName:"ul"},"disabling the ",(0,a.kt)("inlineCode",{parentName:"li"},"read_only")," mode on the primary node (this node will now be able to write to its database)"),(0,a.kt)("li",{parentName:"ul"},"synchronizing/overwriting all the data files (except for the ",(0,a.kt)("inlineCode",{parentName:"li"},"mysql")," system database) "),(0,a.kt)("li",{parentName:"ul"},"unmounting the LVM snapshot"),(0,a.kt)("li",{parentName:"ul"},"creating the replication thread that will keep both databases synchronized")),(0,a.kt)("p",null,"This script's output is very verbose and you can't expect to understand everything, so to make sure it went well, focus on the last lines of its output, checking that it looks like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},'Umount and Delete LVM snapshot\n  Logical volume "dbbackupdatadir" successfully removed\nStart MySQL Slave\nStart Replication\nId  User    Host    db  Command Time    State   Info    Progress\n[variable number of lines]\n')),(0,a.kt)("p",null,"The important thing to check is that ",(0,a.kt)("inlineCode",{parentName:"p"},"Start MySQL Slave")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"Start Replication")," are present and are not followed by any errors."),(0,a.kt)("p",null,"In addition, the output of this command must display only ",(0,a.kt)("inlineCode",{parentName:"p"},"OK")," results:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"/usr/share/centreon-ha/bin/mysql-check-status.sh\n")),(0,a.kt)("p",null,"The expected output is:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"Connection MASTER Status '@DATABASE_MASTER_NAME@' [OK]\nConnection SLAVE Status '@DATABASE_SLAVE_NAME@' [OK]\nSlave Thread Status [OK]\nPosition Status [OK]\n")),(0,a.kt)("h2",{id:"setting-up-the-centreon-cluster"},"Setting up the ",(0,a.kt)("em",{parentName:"h2"},"Centreon")," cluster"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Note"),": unless otherwise stated, each of the following steps must be run ",(0,a.kt)("strong",{parentName:"p"},"on both central nodes (",(0,a.kt)("inlineCode",{parentName:"strong"},"@CENTRAL_MASTER_NAME@")," and ",(0,a.kt)("inlineCode",{parentName:"strong"},"@CENTRAL_SLAVE_NAME@"),")"),"."),(0,a.kt)("h3",{id:"configuring-the-file-synchronization-service"},"Configuring the file synchronization service"),(0,a.kt)("p",null,"The file synchronization ",(0,a.kt)("inlineCode",{parentName:"p"},"centreon-central-sync")," service needs the IP address of the peer node to be entered in its configuration file (",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/centreon-ha/centreon_central_sync.pm"),")."),(0,a.kt)("p",null,"So, on the ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_MASTER_NAME@")," server, the configuration file should look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-perl"},'our %centreon_central_sync_config = (\n    peer_addr => "@CENTRAL_SLAVE_IPADDR@"\n);\n1;\n')),(0,a.kt)("p",null,"And on ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_SLAVE_NAME@"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-perl"},'our %centreon_central_sync_config = (\n    peer_addr => "@CENTRAL_MASTER_IPADDR@"\n);\n1;\n')),(0,a.kt)("h3",{id:"removing-legacy-centreon-cron-jobs"},"Removing legacy Centreon cron jobs"),(0,a.kt)("p",null,"In a high-availability setup, gorgone daemon manages all cron-based scheduled tasks. To avoid cron on both nodes, remove all Centreon-related cron from the /etc/cron.d/ directory:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"rm -f /etc/cron.d/centreon\nrm -f /etc/cron.d/centstorage\nrm -f /etc/cron.d/centreon-auto-disco\nrm -f /etc/cron.d/centreon-ha-mysql\n")),(0,a.kt)("h3",{id:"permission-modifications"},"Permission modifications"),(0,a.kt)("p",null,"Modifications must be made to the permissions for the ",(0,a.kt)("inlineCode",{parentName:"p"},"/var/log/centreon-engine")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"/tmp/centreon-autodisco")," directories."),(0,a.kt)("p",null,"In a clustered setup, it is a requirement to obtain a fully functional file sync and discovery scheduled task. "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"File synchronization")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'chmod 775 /var/log/centreon-engine/\nmkdir /var/log/centreon-engine/archives\nchown centreon-engine: /var/log/centreon-engine/archives\nchmod 775 /var/log/centreon-engine/archives/\nfind /var/log/centreon-engine/ -type f -exec chmod 664 {} \\;\nfind /usr/share/centreon/www/img/media -type d -exec chmod 775 {} \\;\nfind /usr/share/centreon/www/img/media -type f \\( ! -iname ".keep" ! -iname ".htaccess" \\) -exec chmod 664 {} \\;\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Service discovery")),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir /tmp/centreon-autodisco/\nchown apache: /tmp/centreon-autodisco/\nchmod 775 /tmp/centreon-autodisco/\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir /tmp/centreon-autodisco/\nchown www-data: /tmp/centreon-autodisco/\nchmod 775 /tmp/centreon-autodisco/\n")))),(0,a.kt)("h3",{id:"stopping-and-disabling-the-services"},"Stopping and disabling the services"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Information:")," These operations must be applied to all nodes ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_MASTER_NAME@"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_SLAVE_NAME@"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"@DATABASE_MASTER_NAME@")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"@DATABASE_SLAVE_NAME@"),". The entire Centreon suite is installed as a dependency of centreon-ha, but it will not be used on the database nodes and will not cause any trouble."),(0,a.kt)("p",null,"Centreon's application services will no longer be launched at boot time; they will be managed by the clustering tools. These services must therefore be stopped and disabled:"),(0,a.kt)("p",null,"For ",(0,a.kt)("strong",{parentName:"p"}," Central nodes ")),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl stop centengine snmptrapd centreontrapd gorgoned cbd httpd php-fpm centreon\nsystemctl disable centengine snmptrapd centreontrapd gorgoned cbd httpd php-fpm centreon\n"))),(0,a.kt)(l.Z,{value:"Debian 11 ",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl stop centengine snmptrapd centreontrapd gorgoned cbd apache2 php8.1-fpm centreon \nsystemctl disable centengine snmptrapd centreontrapd gorgoned cbd apache2 php8.1-fpm centreon \n")))),(0,a.kt)("p",null,"And for ",(0,a.kt)("strong",{parentName:"p"},"Database nodes")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl stop mysql\nsystemctl disable mysql\n")),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("p",null,"By default, the ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql")," service is enabled in both systemd and system V perspectives, so you should make sure it is disabled:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"chkconfig mysql off\n"))),(0,a.kt)(l.Z,{value:"Debian 11 ",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("p",null,"By default, the ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql")," service is enabled in both systemd and system V perspectives, so you should make sure it is disabled:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"update-rc.d -f mariadb remove\n")))),(0,a.kt)("h3",{id:"creating-the-cluster"},"Creating the cluster"),(0,a.kt)("h4",{id:"activating-the-clustering-services"},"Activating the clustering services"),(0,a.kt)("p",null,"First we enable all the services and start ",(0,a.kt)("inlineCode",{parentName:"p"},"pcsd")," on ",(0,a.kt)("strong",{parentName:"p"},"all nodes"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl start pcsd\n")),(0,a.kt)("h4",{id:"preparing-the-server-that-will-function-as-the-quorum-device"},"Preparing the server that will function as the ",(0,a.kt)("em",{parentName:"h4"},"quorum device")),(0,a.kt)("p",null,"You can use one of your pollers to play this role. It must be prepared with the commands below: "),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma Linux 8",label:"Alma Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf config-manager --enable ha\ndnf install pcs corosync-qnetd\nsystemctl start pcsd.service\nsystemctl enable pcsd.service\npcs qdevice setup model net --enable --start\npcs qdevice status net --full\n"))),(0,a.kt)(l.Z,{value:"RHEL 8",label:"RHEL 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf -y install dnf-plugins-core https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\nsubscription-manager repos --enable rhel-8-for-x86_64-highavailability-rpms\ndnf install pcs corosync-qnetd\nsystemctl start pcsd.service\nsystemctl enable pcsd.service\npcs qdevice setup model net --enable --start\npcs qdevice status net --full\n"))),(0,a.kt)(l.Z,{value:"Oracle Linux 8",label:"Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dnf config-manager --enable ol8_addons\ndnf install pcs corosync-qnetd\nsystemctl start pcsd.service\nsystemctl enable pcsd.service\npcs qdevice setup model net --enable --start\npcs qdevice status net --full\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"apt install pcs corosync-qnetd\nsystemctl start pcsd.service\nsystemctl enable pcsd.service\npcs qdevice setup model net --enable --start\npcs qdevice status net --full\n")))),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("p",null,"Modify the parameter ",(0,a.kt)("inlineCode",{parentName:"p"},"COROSYNC_QNETD_OPTIONS")," in the file ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/sysconfig/corosync-qnetd")," to make sure the service will be listening to the connections on Ipv4 only:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'COROSYNC_QNETD_OPTIONS="-4"\n'))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("p",null,"Modify the parameter ",(0,a.kt)("inlineCode",{parentName:"p"},"COROSYNC_QNETD_OPTIONS")," in the file ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/default/corosync-qnetd")," to make sure the service will be listening to the connections on Ipv4 only"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'COROSYNC_QNETD_OPTIONS="-4"\n')))),(0,a.kt)("h4",{id:"authenticating-to-the-clusters-members"},"Authenticating to the cluster's members"),(0,a.kt)("p",null,"For the sake of simplicity, the ",(0,a.kt)("inlineCode",{parentName:"p"},"hacluster")," user will be assigned the same password on ",(0,a.kt)("strong",{parentName:"p"}," all nodes, ",(0,a.kt)("inlineCode",{parentName:"strong"},"@QDEVICE_NAME@")," included"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"passwd hacluster\n")),(0,a.kt)("p",null,"Now that both central nodes ",(0,a.kt)("strong",{parentName:"p"},"and")," the ",(0,a.kt)("em",{parentName:"p"},"quorum device")," server share the same password, you will run this command ",(0,a.kt)("strong",{parentName:"p"},"only on one of the nodes")," in order to authenticate on all the hosts taking part in the cluster."),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs host auth \\\n    "@CENTRAL_MASTER_NAME@" \\\n    "@CENTRAL_SLAVE_NAME@" \\\n    "@DATABASE_MASTER_NAME@" \\\n    "@DATABASE_SLAVE_NAME@" \\\n    "@QDEVICE_NAME@" \\\n    -u "hacluster" \\\n    -p \'@CENTREON_CLUSTER_PASSWD@\'\n'))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("p",null,"On Debian, the cluster is autoconfigured with default values. In order to install our cluster, we need to destroy this setup using the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs cluster destroy\n")),(0,a.kt)("p",null,"Then you can start the authentication of the cluster:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs host auth \\\n    "@CENTRAL_MASTER_NAME@" \\\n    "@CENTRAL_SLAVE_NAME@" \\\n    "@DATABASE_MASTER_NAME@" \\\n    "@DATABASE_SLAVE_NAME@" \\\n    "@QDEVICE_NAME@" \\\n    -u "hacluster" \\\n    -p \'@CENTREON_CLUSTER_PASSWD@\'\n')))),(0,a.kt)("h4",{id:"creating-the-cluster-1"},"Creating the cluster"),(0,a.kt)("p",null,"The following command creates the cluster. It must be run ",(0,a.kt)("strong",{parentName:"p"},"only on one of the nodes"),"."),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs cluster setup \\\n    centreon_cluster \\\n    "@CENTRAL_MASTER_NAME@" \\\n    "@CENTRAL_SLAVE_NAME@" \\\n    "@DATABASE_MASTER_NAME@" \\\n    "@DATABASE_SLAVE_NAME@" \\\n    --force\n'))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs cluster setup \\\n    centreon_cluster \\\n    "@CENTRAL_MASTER_NAME@" \\\n    "@CENTRAL_SLAVE_NAME@" \\\n    "@DATABASE_MASTER_NAME@" \\\n    "@DATABASE_SLAVE_NAME@" \\\n    --force\n')))),(0,a.kt)("p",null,"Then start the ",(0,a.kt)("inlineCode",{parentName:"p"},"pacemaker")," service ",(0,a.kt)("strong",{parentName:"p"},"on both central and database nodes"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl enable pacemaker pcsd corosync\nsystemctl start pacemaker\n")),(0,a.kt)("p",null,"And afterward define these properties ",(0,a.kt)("strong",{parentName:"p"},"only on one node"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs property set symmetric-cluster="true"\npcs property set stonith-enabled="false"\npcs resource defaults resource-stickiness="100"\n')),(0,a.kt)("p",null,"You can now monitor the state of the cluster with the ",(0,a.kt)("inlineCode",{parentName:"p"},"crm_mon -f")," command, which will display new resources as they appear."),(0,a.kt)("h4",{id:"creating-the-quorum-device"},"Creating the ",(0,a.kt)("em",{parentName:"h4"},"Quorum Device")),(0,a.kt)("p",null,"Run this command on one of the central nodes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs quorum device add model net \\\n    host="@QDEVICE_NAME@" \\\n    algorithm="ffsplit"\n')),(0,a.kt)("h3",{id:"creating-the-mariadb-cluster-resources"},"Creating the MariaDB cluster resources"),(0,a.kt)("p",null,"All commands within this section should be exectued on ",(0,a.kt)("strong",{parentName:"p"},"only one Cluster node"),". The configuration will be spread automatically."),(0,a.kt)("h4",{id:"primary--secondary-mysql-processes"},"Primary & Secondary MySQL Processes"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create "ms_mysql" \\\n    ocf:heartbeat:mariadb-centreon \\\n    config="/etc/my.cnf.d/server.cnf" \\\n    pid="/var/lib/mysql/mysql.pid" \\\n    datadir="/var/lib/mysql" \\\n    socket="/var/lib/mysql/mysql.sock" \\\n    binary="/usr/bin/mysqld_safe" \\\n    node_list="@DATABASE_MASTER_NAME@ @DATABASE_SLAVE_NAME@" \\\n    replication_user="@MARIADB_REPL_USER@" \\\n    replication_passwd=\'@MARIADB_REPL_PASSWD@\' \\\n    test_user="@MARIADB_REPL_USER@" \\\n    test_passwd=\'@MARIADB_REPL_PASSWD@\' \\\n    test_table=\'centreon.host\'\n'))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create "ms_mysql" \\\n    ocf:heartbeat:mariadb-centreon \\\n    config="/etc/mysql/mariadb.conf.d/50-server.cnf" \\\n    pid="/run/mysqld/mysqld.pid" \\\n    datadir="/var/lib/mysql" \\\n    socket="/run/mysqld/mysqld.sock" \\\n    binary="/usr/bin/mysqld_safe" \\\n    node_list="@CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@" \\\n    replication_user="@MARIADB_REPL_USER@" \\\n    replication_passwd=\'@MARIADB_REPL_PASSWD@\' \\\n    test_user="@MARIADB_REPL_USER@" \\\n    test_passwd=\'@MARIADB_REPL_PASSWD@\' \\\n    test_table=\'centreon.host\'\n')))),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"WARNING:")," the syntax of the following command depends on the Linux Distribution you are using.")),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource promotable ms_mysql \\\n    master-node-max="1" \\\n    clone_max="2" \\\n    globally-unique="false" \\\n    clone-node-max="1" \\\n    notify="true"\n'))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource promotable ms_mysql \\\n    master-node-max="1" \\\n    clone_max="2" \\\n    globally-unique="false" \\\n    clone-node-max="1" \\\n    notify="true"\n')))),(0,a.kt)("h4",{id:"mariadb-virtual-ip-address"},"MariaDB Virtual IP Address"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create vip_mysql \\\n    ocf:heartbeat:IPaddr2 \\\n    ip="@VIP_SQL_IPADDR@" \\\n    nic="@VIP_SQL_IFNAME@" \\\n    cidr_netmask="@VIP_SQL_CIDR_NETMASK@" \\\n    broadcast="@VIP_SQL_BROADCAST_IPADDR@" \\\n    flush_routes="true" \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="20s" \\\n    stop interval="0s" timeout="20s" \\\n    monitor interval="10s" timeout="20s"\n')),(0,a.kt)("h3",{id:"creating-the-clone-resources"},"Creating the clone resources"),(0,a.kt)("p",null,"Some resources must be running on only one node at a time (",(0,a.kt)("inlineCode",{parentName:"p"},"centengine"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"gorgone"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"httpd"),", ...), but some others can be running on both (the RRD broker and PHP). For the second kind, you must declare ",(0,a.kt)("em",{parentName:"p"},"clone")," resources."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("strong",{parentName:"p"},"Warning:")," All the commands in this chapter should be run only once on the central node of your choice.")),(0,a.kt)("h5",{id:"php8-resource"},"PHP8 resource"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},'```bash pcs resource create "php" \\ systemd:php-fpm \\ meta target-role="started" \\ op start interval="0s" timeout="30s" \\ stop interval="0s" timeout="30s" \\ monitor interval="5s" timeout="30s" \\ clone ```'),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create "php" \\\n    systemd:php8.1-fpm \\\n    meta target-role="started" \\\n    op start interval="0s" timeout="30s" \\\n    stop interval="0s" timeout="30s" \\\n    monitor interval="5s" timeout="30s" \\\n    clone\n')))),(0,a.kt)("h5",{id:"rrd-broker-resource"},"RRD broker resource"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create "cbd_rrd" \\\n    systemd:cbd \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="90s" \\\n    stop interval="0s" timeout="90s" \\\n    monitor interval="20s" timeout="30s" \\\n    clone\n')),(0,a.kt)("h3",{id:"creating-the-centreon-resource-group"},"Creating the ",(0,a.kt)("em",{parentName:"h3"},"centreon")," resource group"),(0,a.kt)("h4",{id:"web-vip-address"},"Web VIP address"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create vip \\\n    ocf:heartbeat:IPaddr2 \\\n    ip="@VIP_IPADDR@" \\\n    nic="@VIP_IFNAME@" \\\n    cidr_netmask="@VIP_CIDR_NETMASK@" \\\n    broadcast="@VIP_BROADCAST_IPADDR@" \\\n    flush_routes="true" \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="20s" \\\n    stop interval="0s" timeout="20s" \\\n    monitor interval="10s" timeout="20s" \\\n    --group centreon\n')),(0,a.kt)("h4",{id:"httpd-service"},"Httpd service"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create http \\\n    systemd:httpd \\\n    meta target-role="started" \\\n    op start interval="0s" timeout="40s" \\\n    stop interval="0s" timeout="40s" \\\n    monitor interval="5s" timeout="20s" \\\n    --group centreon \\\n    --force\n'))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create http \\\n    systemd:apache2 \\\n    meta target-role="started" \\\n    op start interval="0s" timeout="40s" \\\n    stop interval="0s" timeout="40s" \\\n    monitor interval="5s" timeout="20s" \\\n    --group centreon \\\n    --force\n')))),(0,a.kt)("h4",{id:"gorgone-service"},"Gorgone service"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create gorgone \\\n    systemd:gorgoned \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="90s" \\\n    stop interval="0s" timeout="90s" \\\n    monitor interval="5s" timeout="20s" \\\n    --group centreon\n')),(0,a.kt)("h4",{id:"centreon-central-sync-service"},"centreon-central-sync service"),(0,a.kt)("p",null,"This service only exists in the context of ",(0,a.kt)("em",{parentName:"p"},"Centreon HA"),". It provides real-time synchronization for configuration files, images, etc."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create centreon_central_sync \\\n    systemd:centreon-central-sync \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="90s" \\\n    stop interval="0s" timeout="90s" \\\n    monitor interval="5s" timeout="20s" \\\n    --group centreon\n')),(0,a.kt)("h4",{id:"sql-broker"},"SQL Broker"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create cbd_central_broker \\\n    systemd:cbd-sql \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="90s" \\\n    stop interval="0s" timeout="90s" \\\n    monitor interval="5s" timeout="30s" \\\n    --group centreon\n')),(0,a.kt)("h4",{id:"centengine-service"},"Centengine service"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create centengine \\\n    systemd:centengine \\\n    meta multiple-active="stop_start" target-role="stopped" \\\n    op start interval="0s" timeout="90s" stop interval="0s" timeout="90s" \\\n    monitor interval="5s" timeout="30s" \\\n    --group centreon\n')),(0,a.kt)("h4",{id:"centreontrapd-service"},"Centreontrapd service"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create centreontrapd \\\n    systemd:centreontrapd \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="30s" \\\n    stop interval="0s" timeout="30s" \\\n    monitor interval="5s" timeout="20s" \\\n    --group centreon\n')),(0,a.kt)("h4",{id:"snmptrapd-service"},"Snmptrapd service"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource create snmptrapd \\\n    systemd:snmptrapd \\\n    meta target-role="stopped" \\\n    op start interval="0s" timeout="30s" \\\n    stop interval="0s" timeout="30s" \\\n    monitor interval="5s" timeout="20s" \\\n    --group centreon\n')),(0,a.kt)("h3",{id:"resource-constraints"},"Resource constraints"),(0,a.kt)("p",null,"When using the four-node architecture, you must define some specific constraints to specify where resources could run. "),(0,a.kt)("p",null,"In order to colocate the Primary Database role with the Virtual IP, define a mutual constraint:"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs constraint colocation add "vip_mysql" with master "ms_mysql-clone"\npcs constraint colocation add master "ms_mysql-clone" with "vip_mysql"\n'))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs constraint colocation add "vip_mysql" with master "ms_mysql-clone"\npcs constraint colocation add master "ms_mysql-clone" with "vip_mysql"\n')))),(0,a.kt)("p",null,"Create the constraint that prevents Centreon Processes from running on Database nodes and vice-versa: "),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs constraint location centreon avoids @DATABASE_MASTER_NAME@=INFINITY @DATABASE_SLAVE_NAME@=INFINITY\npcs constraint location ms_mysql-clone avoids @CENTRAL_MASTER_NAME@=INFINITY @CENTRAL_SLAVE_NAME@=INFINITY\npcs constraint location cbd_rrd-clone avoids @DATABASE_MASTER_NAME@=INFINITY @DATABASE_SLAVE_NAME@=INFINITY\npcs constraint location php-clone avoids @DATABASE_MASTER_NAME@=INFINITY @DATABASE_SLAVE_NAME@=INFINITY\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs constraint location centreon avoids @DATABASE_MASTER_NAME@=INFINITY @DATABASE_SLAVE_NAME@=INFINITY\npcs constraint location ms_mysql-clone avoids @CENTRAL_MASTER_NAME@=INFINITY @CENTRAL_SLAVE_NAME@=INFINITY\npcs constraint location cbd_rrd-clone avoids @DATABASE_MASTER_NAME@=INFINITY @DATABASE_SLAVE_NAME@=INFINITY\npcs constraint location php-clone avoids @DATABASE_MASTER_NAME@=INFINITY @DATABASE_SLAVE_NAME@=INFINITY\n")))),(0,a.kt)("h3",{id:"activate-the-cluster-and-check-the-operating-state-of-the-resources"},"Activate the cluster and check the operating state of the resources"),(0,a.kt)("h4",{id:"enable-resources"},"Enable resources"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'pcs resource enable php-clone\npcs resource enable cbd_rrd-clone\npcs resource meta vip target-role="started"\npcs resource meta vip_mysql target-role="started"\npcs resource meta centreontrapd target-role="started"\npcs resource meta snmptrapd target-role="started"\npcs resource meta centengine target-role="started"\npcs resource meta cbd_central_broker target-role="started"\npcs resource meta gorgone target-role="started"\npcs resource meta centreon_central_sync target-role="started"\npcs resource meta http target-role="started"\n')),(0,a.kt)("h3",{id:"checking-the-state-of-the-cluster"},"Checking the state of the cluster"),(0,a.kt)("h4",{id:"checking-the-states-of-the-resources"},"Checking the states of the resources"),(0,a.kt)("p",null,"You can monitor the cluster's resources in real time using the ",(0,a.kt)("inlineCode",{parentName:"p"},"crm_mon -fr")," command:"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"Cluster Summary:\n  * Stack: corosync\n  * Current DC: @CENTRAL_MASTER_NAME@ (version 2.0.5-9.0.1.el8_4.1-ba59be7122) - partition with quorum\n  * Last updated: Wed Sep 22 15:00:13 2021\n  * Last change:  Wed Sep 15 16:26:53 2021 by root via crm_attribute on @CENTRAL_MASTER_NAME@\n  * 4 nodes configured\n  * 21 resource instances configured\n\nNode List:\n  * Online: [ @DATABASE_MASTER_NAME@ @DATABASE_SLAVE_NAME@ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n\nActive Resources:\n  * Clone Set: ms_mysql-clone [ms_mysql] (promotable):\n    * Masters: [ @DATABASE_MASTER_NAME@ ]\n    * Slaves: [ @DATABASE_SLAVE_NAME@ ]\n  * vip_mysql   (ocf::heartbeat:IPaddr2):        Started @DATABASE_MASTER_NAME@\n  * Clone Set: php-clone [php]:\n    * Started: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n  * Clone Set: cbd_rrd-clone [cbd_rrd]:\n    * Started: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n  * Resource Group: centreon:\n    * vip       (ocf::heartbeat:IPaddr2):        Started @CENTRAL_MASTER_NAME@\n    * http      (systemd:httpd):         Started @CENTRAL_MASTER_NAME@\n    * gorgone   (systemd:gorgoned):      Started @CENTRAL_MASTER_NAME@\n    * centreon_central_sync     (systemd:centreon-central-sync):         Started @CENTRAL_MASTER_NAME@\n    * cbd_central_broker        (systemd:cbd-sql):       Started @CENTRAL_MASTER_NAME@\n    * centengine        (systemd:centengine):    Started @CENTRAL_MASTER_NAME@\n    * centreontrapd     (systemd:centreontrapd):         Started @CENTRAL_MASTER_NAME@\n    * snmptrapd (systemd:snmptrapd):     Started @CENTRAL_MASTER_NAME@\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"Cluster Summary:\n  * Stack: corosync\n  * Current DC: @CENTRAL_MASTER_NAME@ (version 2.0.5-9.0.1.el8_4.1-ba59be7122) - partition with quorum\n  * Last updated: Wed Sep 22 15:00:13 2021\n  * Last change:  Wed Sep 15 16:26:53 2021 by root via crm_attribute on @CENTRAL_MASTER_NAME@\n  * 4 nodes configured\n  * 21 resource instances configured\n\nNode List:\n  * Online: [ @DATABASE_MASTER_NAME@ @DATABASE_SLAVE_NAME@ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n\nActive Resources:\n  * Clone Set: ms_mysql-clone [ms_mysql] (promotable):\n    * Masters: [ @DATABASE_MASTER_NAME@ ]\n    * Slaves: [ @DATABASE_SLAVE_NAME@ ]\n  * vip_mysql   (ocf::heartbeat:IPaddr2):        Started @DATABASE_MASTER_NAME@\n  * Clone Set: php-clone [php]:\n    * Started: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n  * Clone Set: cbd_rrd-clone [cbd_rrd]:\n    * Started: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n  * Resource Group: centreon:\n    * vip       (ocf::heartbeat:IPaddr2):        Started @CENTRAL_MASTER_NAME@\n    * http      (systemd:httpd):         Started @CENTRAL_MASTER_NAME@\n    * gorgone   (systemd:gorgoned):      Started @CENTRAL_MASTER_NAME@\n    * centreon_central_sync     (systemd:centreon-central-sync):         Started @CENTRAL_MASTER_NAME@\n    * cbd_central_broker        (systemd:cbd-sql):       Started @CENTRAL_MASTER_NAME@\n    * centengine        (systemd:centengine):    Started @CENTRAL_MASTER_NAME@\n    * centreontrapd     (systemd:centreontrapd):         Started @CENTRAL_MASTER_NAME@\n    * snmptrapd (systemd:snmptrapd):     Started @CENTRAL_MASTER_NAME@\n")))),(0,a.kt)("p",null,"If ",(0,a.kt)("strong",{parentName:"p"},"centreon_central_sync")," won't start, check if the folder ",(0,a.kt)("inlineCode",{parentName:"p"},"/usr/share/centreon-broker/lua")," exists ",(0,a.kt)("strong",{parentName:"p"},"on both central nodes"),"."),(0,a.kt)("p",null,"If not, you can create it with this command: ",(0,a.kt)("inlineCode",{parentName:"p"},"mkdir -p /usr/share/centreon-broker/lua"),". And launch a cleanup with this command: ",(0,a.kt)("inlineCode",{parentName:"p"},"pcs resource cleanup"),"."),(0,a.kt)("h4",{id:"disabled-resources"},"Disabled resources"),(0,a.kt)("p",null,"When you do a ",(0,a.kt)("inlineCode",{parentName:"p"},"crm_mon -fr")," and you have a resource that is disabled:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"...\n Master/Slave Set: ms_mysql-master [ms_mysql]\n     Masters: [ @DATABASE_MASTER_NAME@ ]\n     Slaves: [ @DATABASE_SLAVE_NAME@ ]\n     Stopped: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\nvip_mysql       (ocf::heartbeat:IPaddr2):       Stopped (disabled)\n...\n")),(0,a.kt)("p",null,"You must enable the resource with the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs resource enable @RESSOURCE_NAME@\n")),(0,a.kt)("p",null,"In our case:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs resource enable vip_mysql\n")),(0,a.kt)("h4",{id:"checking-the-database-replication-thread"},"Checking the database replication thread"),(0,a.kt)("p",null,"The MariaDB replication state can be monitored at any time with the ",(0,a.kt)("inlineCode",{parentName:"p"},"mysql-check-status.sh")," command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"/usr/share/centreon-ha/bin/mysql-check-status.sh\n")),(0,a.kt)("p",null,"The expected output is:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"Connection MASTER Status '@DATABASE_MASTER_NAME@' [OK]\nConnection SLAVE Status '@DATABASE_SLAVE_NAME@' [OK]\nSlave Thread Status [OK]\nPosition Status [OK]\n")),(0,a.kt)("p",null,"It can happen that the replication thread does not run properly after installation.  Restarting the ",(0,a.kt)("inlineCode",{parentName:"p"},"ms_mysql")," resource may fix it."),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs resource restart ms_mysql-clone\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs resource restart ms_mysql-clone\n")))),(0,a.kt)("h4",{id:"checking-the-constraints"},"Checking the constraints"),(0,a.kt)("p",null,"Normally, the two colocation constraints created during the setup should be the only constraints the ",(0,a.kt)("inlineCode",{parentName:"p"},"pcs constraint")," command displays:"),(0,a.kt)(r.Z,{groupId:"sync",mdxType:"Tabs"},(0,a.kt)(l.Z,{value:"Alma / RHEL / Oracle Linux 8",label:"Alma / RHEL / Oracle Linux 8",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"Location Constraints:\n  Resource: cbd_rrd-clone\n    Disabled on: @DATABASE_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @DATABASE_SLAVE_NAME@ (score:-INFINITY)\n  Resource: centreon\n    Disabled on: @DATABASE_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @DATABASE_SLAVE_NAME@ (score:-INFINITY)\n  Resource: ms_mysql-clone\n    Disabled on: @CENTRAL_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @CENTRAL_SLAVE_NAME@ (score:-INFINITY)\n  Resource: php-clone\n    Disabled on: @DATABASE_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @DATABASE_SLAVE_NAME@ (score:-INFINITY)\nOrdering Constraints:\nColocation Constraints:\n  vip_mysql with ms_mysql-clone (score:INFINITY) (rsc-role:Started) (with-rsc-role:Master)\n  ms_mysql-clone with vip_mysql (score:INFINITY) (rsc-role:Master) (with-rsc-role:Started)\nTicket Constraints:\n"))),(0,a.kt)(l.Z,{value:"Debian 11",label:"Debian 11",mdxType:"TabItem"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"Location Constraints:\n  Resource: cbd_rrd-clone\n    Disabled on: @DATABASE_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @DATABASE_SLAVE_NAME@ (score:-INFINITY)\n  Resource: centreon\n    Disabled on: @DATABASE_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @DATABASE_SLAVE_NAME@ (score:-INFINITY)\n  Resource: ms_mysql-clone\n    Disabled on: @CENTRAL_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @CENTRAL_SLAVE_NAME@ (score:-INFINITY)\n  Resource: php-clone\n    Disabled on: @DATABASE_MASTER_NAME@ (score:-INFINITY)\n    Disabled on: @DATABASE_SLAVE_NAME@ (score:-INFINITY)\nOrdering Constraints:\nColocation Constraints:\n  vip_mysql with ms_mysql-clone (score:INFINITY) (rsc-role:Started) (with-rsc-role:Master)\n  ms_mysql-clone with vip_mysql (score:INFINITY) (rsc-role:Master) (with-rsc-role:Started)\nTicket Constraints:\n")))),(0,a.kt)("h2",{id:"modifying-the-centreon-configuration-files"},"Modifying the Centreon configuration files"),(0,a.kt)("p",null,"Following the installation of the cluster and the ",(0,a.kt)("em",{parentName:"p"},"vip_mysql"),", it is necessary to modify the output of the Centreon Broker and three configuration files of the Central. These elements will have to point to the ",(0,a.kt)("em",{parentName:"p"},"vip_mysql")," in order to always point to the active MariaDB node.\nThese three files are:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"/etc/centreon/centreon.conf.php"),(0,a.kt)("li",{parentName:"ul"},"/etc/centreon/conf.pm"),(0,a.kt)("li",{parentName:"ul"},"/etc/centreon/config.d/10-database.yaml\nYou will need to replace the IP of the previous database with the IP of the ",(0,a.kt)("em",{parentName:"li"},"vip_mysql"))),(0,a.kt)("h3",{id:"modifying-central-broker-master-outputs"},"Modifying central-broker-master outputs"),(0,a.kt)("p",null,"This is configured in the Centreon Broker configuration menu in the ",(0,a.kt)("em",{parentName:"p"},"Output")," tab of ",(0,a.kt)("em",{parentName:"p"},"Configuration > Collectors > Centreon Broker Configuration"),"."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'Modify the "IPv4" output by replacing "@DATABASE_MASTER_IPADDR@" with @VIP_SQL_IPADDR@ in ',(0,a.kt)("em",{parentName:"li"},"central-broker-master")," configuration:")),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Broker Output"),(0,a.kt)("th",{parentName:"tr",align:null},"Parameter"),(0,a.kt)("th",{parentName:"tr",align:null},"Value"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Unified SQL"),(0,a.kt)("td",{parentName:"tr",align:null},"DB host"),(0,a.kt)("td",{parentName:"tr",align:null},"@VIP_SQL_IPADDR@")))),(0,a.kt)("h3",{id:"exporting-configuration"},"Exporting configuration"),(0,a.kt)("p",null,'Once the actions in the previous paragraph have been completed, the configuration must be exported (first three boxes for the "Central" poller export) for it to take effect.'),(0,a.kt)("p",null,"These actions must be performed only on ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_MASTER_NAME@")," and then the broker configuration files must be copied to ",(0,a.kt)("inlineCode",{parentName:"p"},"@CENTRAL_SLAVE_NAME@"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"rsync -a /etc/centreon-broker/*json @CENTRAL_SLAVE_IPADDR@:/etc/centreon-broker/\n")),(0,a.kt)("h3",{id:"modification-of-the-three-configuration-files"},"Modification of the three configuration files"),(0,a.kt)("p",null,"After modifying the output of the broker, we must modify the Centreon configuration files.\nTo do this, first, edit the file ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/centreon/conf.pm")," and replace @DATABASE",(0,a.kt)("em",{parentName:"p"},"MASTER_IPADDR@ with the address of the _vip-mysql"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'#############################################\n# File Added by Centreon\n#\n$centreon_config = {\n       VarLib => "/var/lib/centreon",\n       CentreonDir => "/usr/share/centreon/",\n       CacheDir => "/var/cache/centreon/",\n       "centreon_db" => "centreon",\n       "centstorage_db" => "centreon_storage",\n       "db_host" => "@VIP_SQL_IPADDR@:3306",\n       "db_user" => "@MARIADB_CENTREON_USER@",\n       "db_passwd" => \'@MARIADB_CENTREON_PASSWD@\'\n};\n# Central or Poller?\n$instance_mode = "central";\n# Centreon Centcore Command File\n$cmdFile = "/var/lib/centreon/centcore.cmd";\n# Deprecated format of Config file.\n$mysql_user = "@MARIADB_CENTREON_USER@";\n$mysql_passwd = \'@MARIADB_CENTREON_PASSWD@\';\n$mysql_host = "@VIP_SQL_IPADDR@:3306";\n$mysql_database_oreon = "centreon";\n$mysql_database_ods = "centreon_storage";\n1;\n')),(0,a.kt)("p",null,"Then perform the same operation in the file ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/centreon/centreon.conf.php"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"<?php\n/*\n * Centreon is developed with GPL Licence 2.0:\n * http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt\n * Developed by: Julien Mathis - Romain Le Merlus - Christophe Coraboeuf\n *\n * The Software is provided to you AS IS and WITH ALL FAULTS.\n * Centreon makes no representation and gives no warranty whatsoever,\n * whether express or implied, and without limitation, with regard to the quality,\n * safety, contents, performance, merchantability, non-infringement or suitability for\n * any particular or intended purpose of the Software found on the Centreon website.\n * In no event will Centreon be liable for any direct, indirect, punitive, special,\n * incidental or consequential damages however they may arise and even if Centreon has\n * been previously advised of the possibility of such damages.\n *\n * For information: contact@centreon.com\n */\n/*      Database */\n$conf_centreon['hostCentreon'] = \"@VIP_SQL_IPADDR@\";\n$conf_centreon['hostCentstorage'] = \"@VIP_SQL_IPADDR@\";\n$conf_centreon['user'] = \"@MARIADB_CENTREON_USER@\";\n$conf_centreon['password'] = '@MARIADB_CENTREON_PASSWD@';\n$conf_centreon['db'] = \"centreon\";\n$conf_centreon['dbcstg'] = \"centreon_storage\";\n$conf_centreon['port'] = \"3306\";\n/* path to classes */\n$classdir='./class';\n/* Centreon Path */\n$centreon_path='/usr/share/centreon/';\n?>\n")),(0,a.kt)("p",null,"And finish with the last file ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/centreon/config.d/10-database.yaml"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'database:\n  db_configuration:\n    dsn: "mysql:host=@VIP_SQL_IPADDR@:3306;dbname=centreon"\n    username: "@MARIADB_CENTREON_USER@"\n    password: "@MARIADB_CENTREON_PASSWD@"\n  db_realtime:\n    dsn: "mysql:host=@VIP_SQL_IPADDR@:3306;dbname=centreon_storage"\n    username: "@MARIADB_CENTREON_USER@"\n    password: "@MARIADB_CENTREON_PASSWD@"\n')),(0,a.kt)("p",null,"And then you need to restart the gorgone and cbd_central_broker resources for changes to take effect.\nUse the following command to restart the gorgone resource and all subsequent resources:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs resource restart gorgone\n")),(0,a.kt)("p",null,"After resources are restarted, verify if all is OK using the command ",(0,a.kt)("inlineCode",{parentName:"p"},"crm_mon -fr"),". The result should look like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-text"},"Cluster Summary:\n  * Stack: corosync\n  * Current DC: @CENTRAL_MASTER_NAME@ (version 2.1.4-5.el8_7.2-dc6eb4362e) - partition with quoru\nm\n  * Last updated: Wed Nov 23 10:27:48 2022\n  * Last change:  Wed Nov 23 10:27:43 2022 by hacluster via crmd on @CENTRAL_MASTER_NAME@\n  * 4 nodes configured\n  * 21 resource instances configured\n\nNode List:\n  * Online: [ @CENTRAL_MASTER_NAME@ centreon-rhel8-pri-bdd @CENTRAL_SLAVE_NAME@ @DATABASE_SLAVE_NAME@\n]\n\nFull List of Resources:\n  * Clone Set: ms_mysql-clone [ms_mysql] (promotable):\n    * Masters: [ centreon-rhel8-pri-bdd ]\n    * Slaves: [ @DATABASE_SLAVE_NAME@ ]\n    * Stopped: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n  * vip_mysql   (ocf::heartbeat:IPaddr2):        Started centreon-rhel8-pri-bdd\n  * Clone Set: php-clone [php]:\n    * Started: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n    * Stopped: [ centreon-rhel8-pri-bdd @DATABASE_SLAVE_NAME@ ]\n  * Clone Set: cbd_rrd-clone [cbd_rrd]:\n    * Started: [ @CENTRAL_MASTER_NAME@ @CENTRAL_SLAVE_NAME@ ]\n    * Stopped: [ centreon-rhel8-pri-bdd @DATABASE_SLAVE_NAME@ ]\n  * Resource Group: centreon:\n    * vip       (ocf::heartbeat:IPaddr2):        Started @CENTRAL_MASTER_NAME@\n    * http      (systemd:httpd):         Started @CENTRAL_MASTER_NAME@\n    * gorgone   (systemd:gorgoned):      Started @CENTRAL_MASTER_NAME@\n    * centreon_central_sync     (systemd:centreon-central-sync):         Started @CENTRAL_MASTER_NAME@\n    * cbd_central_broker        (systemd:cbd-sql):       Started @CENTRAL_MASTER_NAME@\n    * centengine        (systemd:centengine):    Started @CENTRAL_MASTER_NAME@\n    * centreontrapd     (systemd:centreontrapd):         Started@CENTRAL_MASTER_NAME@\n    * snmptrapd (systemd:snmptrapd):     Started @CENTRAL_MASTER_NAME@\n\nMigration Summary:\n")),(0,a.kt)("p",null,'If an error is found while your resources are running, try doing some "cleaning" using this command:'),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pcs resource cleanup\n")),(0,a.kt)("h2",{id:"integrating-pollers"},"Integrating pollers"),(0,a.kt)("p",null,"You can now ",(0,a.kt)("a",{parentName:"p",href:"/centreon-documentation/pr-preview/staging/pr-2596/docs/installation/installation-of-centreon-ha/integrating-pollers"},"add your pollers")," and begin to monitor!"))}N.isMDXComponent=!0}}]);